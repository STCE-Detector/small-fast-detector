{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T14:30:15.277429Z",
     "start_time": "2024-05-01T14:30:15.270455Z"
    }
   },
   "cell_type": "code",
   "source": "import jetson_utils",
   "id": "3060732cf702c522",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T14:30:15.423310Z",
     "start_time": "2024-05-01T14:30:15.303378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "#!/usr/bin/env python3\n",
    "import io\n",
    "import PIL\n",
    "import logging\n",
    "import torch\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from jetson_utils import cudaImage, cudaFromNumpy\n",
    "\n",
    "\n",
    "ImageTypes = (PIL.Image.Image, np.ndarray, torch.Tensor, cudaImage)\n",
    "ImageExtensions = ('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')\n",
    "\n",
    "\n",
    "def is_image(image):\n",
    "    \"\"\"\n",
    "    Returns true if the object is a PIL.Image, np.ndarray, torch.Tensor, or jetson_utils.cudaImage\n",
    "    \"\"\"\n",
    "    return isinstance(image, ImageTypes)\n",
    "    \n",
    " \n",
    "def image_size(image):\n",
    "    \"\"\"\n",
    "    Returns the dimensions of the image as a ``(height, width, channels)`` tuple.\n",
    "    \"\"\"\n",
    "    if isinstance(image, (cudaImage, np.ndarray, torch.Tensor)):\n",
    "        return image.shape\n",
    "    elif isinstance(image, PIL.Image.Image):\n",
    "        return image.size\n",
    "    else:\n",
    "        raise TypeError(f\"expected an image of type {ImageTypes} (was {type(image)})\")\n",
    "        \n",
    "    \n",
    "def load_image(path):\n",
    "    \"\"\"\n",
    "    Load an image from a local path or URL that will be downloaded.\n",
    "    \n",
    "    Args:\n",
    "      path (str): either a path or URL to the image.\n",
    "      \n",
    "    Returns:\n",
    "      ``PIL.Image`` instance\n",
    "    \"\"\"\n",
    "    if path.startswith('http') or path.startswith('https'):\n",
    "        logging.debug(f'-- downloading {path}')\n",
    "        response = requests.get(path)\n",
    "        image = PIL.Image.open(io.BytesIO(response.content)).convert('RGB')\n",
    "    else:\n",
    "        logging.debug(f'-- loading {path}')\n",
    "        image = PIL.Image.open(path).convert('RGB')\n",
    "        \n",
    "    return image\n",
    "\n",
    "\n",
    "def cuda_image(image):\n",
    "    \"\"\"\n",
    "    Convert an image from `PIL.Image`, `np.ndarray`, `torch.Tensor`, or `__gpu_array_interface__`\n",
    "    to a jetson_utils.cudaImage on the GPU (without using memory copies when possible)\n",
    "    \"\"\"   \n",
    "    # TODO implement __gpu_array_interface__\n",
    "    # TODO torch image formats https://github.com/dusty-nv/jetson-utils/blob/f0bff5c502f9ac6b10aa2912f1324797df94bc2d/python/examples/cuda-from-pytorch.py#L47\n",
    "    if not is_image(image):\n",
    "        raise TypeError(f\"expected an image of type {ImageTypes} (was {type(image)})\")\n",
    "        \n",
    "    if isinstance(image, cudaImage):\n",
    "        return image\n",
    "        \n",
    "    if isinstance(image, PIL.Image.Image):\n",
    "        image = np.asarray(image)  # no copy\n",
    "        \n",
    "    if isinstance(image, np.ndarray):\n",
    "        return cudaFromNumpy(image)\n",
    "        \n",
    "    if isinstance(image, torch.Tensor):\n",
    "        input = input.to(memory_format=torch.channels_last)   # or tensor.permute(0, 3, 2, 1)\n",
    "        \n",
    "        return cudaImage(\n",
    "            ptr=input.data_ptr(), \n",
    "            width=input.shape[-1], \n",
    "            height=input.shape[-2], \n",
    "            format=torch_image_format(input)\n",
    "        )\n",
    "        \n",
    " \n",
    "def torch_image(image, dtype=None, device=None):\n",
    "    \"\"\"\n",
    "    Convert the image to a type that is compatible with PyTorch ``(torch.Tensor, ndarray, PIL.Image)``\n",
    "    \"\"\"\n",
    "    if not isinstance(image, ImageTypes):\n",
    "        raise TypeError(f\"expected an image of type {ImageTypes} (was {type(image)})\")\n",
    "        \n",
    "    if isinstance(image, cudaImage):\n",
    "        return torch.as_tensor(image, dtype=dtype, device=device)\n",
    "    elif isinstance(image, (PIL.Image.Image, np.ndarray)):\n",
    "        image = F.to_tensor(image)\n",
    "\n",
    "    return image.to(dtype=dtype, device=device)\n",
    "        \n",
    "        \n",
    "def torch_image_format(tensor):\n",
    "    \"\"\"\n",
    "    Determine the cudaImage format string (eg 'rgb32f', 'rgba32f', ect) from a PyTorch tensor.\n",
    "    Only float and uint8 tensors are supported because those datatypes are supported by cudaImage.\n",
    "    \"\"\"\n",
    "    if tensor.dtype != torch.float32 and tensor.dtype != torch.uint8:\n",
    "        raise ValueError(f\"PyTorch tensor datatype should be torch.float32 or torch.uint8 (was {tensor.dtype})\")\n",
    "        \n",
    "    if len(tensor.shape)>= 4:     # NCHW layout\n",
    "        channels = tensor.shape[1]\n",
    "    elif len(tensor.shape) == 3:   # CHW layout\n",
    "        channels = tensor.shape[0]\n",
    "    elif len(tensor.shape) == 2:   # HW layout\n",
    "        channels = 1\n",
    "    else:\n",
    "        raise ValueError(f\"PyTorch tensor should have at least 2 image dimensions (has {tensor.shape.length})\")\n",
    "        \n",
    "    if channels == 1:   return 'gray32f' if tensor.dtype == torch.float32 else 'gray8'\n",
    "    elif channels == 3: return 'rgb32f'  if tensor.dtype == torch.float32 else 'rgb8'\n",
    "    elif channels == 4: return 'rgba32f' if tensor.dtype == torch.float32 else 'rgba8'\n",
    "    \n",
    "    raise ValueError(f\"PyTorch tensor should have 1, 3, or 4 image channels (has {channels})\")"
   ],
   "id": "49361c5b3aa59b4f",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T14:30:15.631639Z",
     "start_time": "2024-05-01T14:30:15.425648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#!/usr/bin/env python3\n",
    "import time\n",
    "import queue\n",
    "import threading\n",
    "import logging\n",
    "import traceback\n",
    "\n",
    "\n",
    "class Plugin(threading.Thread):\n",
    "    \"\"\"\n",
    "    Base class for plugins that process incoming/outgoing data from connections\n",
    "    with other plugins, forming a pipeline or graph.  Plugins can run either\n",
    "    single-threaded or in an independent thread that processes data out of a queue.\n",
    "\n",
    "    Frequent categories of plugins:\n",
    "    \n",
    "      * sources:  text prompts, images/video\n",
    "      * process:  LLM queries, RAG, dynamic LLM calls, image post-processors\n",
    "      * outputs:  print to stdout, save images/video\n",
    "      \n",
    "    Inherited plugins should implement the :func:`process` function to handle incoming data.\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "      output_channels (int): the number of sets of output connections the plugin has\n",
    "      relay (bool): if true, will relay any inputs as outputs after processing\n",
    "      drop_inputs (bool): if true, only the most recent input in the queue will be used\n",
    "      threaded (bool): if true, will spawn independent thread for processing the queue.\n",
    "    \"\"\"\n",
    "    def __init__(self, output_channels=1, relay=False, drop_inputs=False, threaded=True, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize plugin\n",
    "        \"\"\"\n",
    "        super().__init__(daemon=True)\n",
    "\n",
    "        self.relay = relay\n",
    "        self.drop_inputs = drop_inputs\n",
    "        self.threaded = threaded\n",
    "        self.interrupted = False\n",
    "        self.processing = False\n",
    "        \n",
    "        self.outputs = [[] for i in range(output_channels)]\n",
    "        self.output_channels = output_channels\n",
    "        \n",
    "        if threaded:\n",
    "            self.input_queue = queue.Queue()\n",
    "            self.input_event = threading.Event()\n",
    "\n",
    "    def process(self, input, **kwargs):\n",
    "        \"\"\"\n",
    "        Abstract function that plugin instances should implement to process incoming data.\n",
    "        Don't call this function externally unless ``threaded=False``, because\n",
    "        otherwise the plugin's internal thread dispatches from the queue.\n",
    "\n",
    "        Args:\n",
    "        \n",
    "          input: input data to process from the previous plugin in the pipeline\n",
    "          kwargs: optional processing arguments that accompany this data\n",
    "          \n",
    "        Returns:\n",
    "        \n",
    "          Plugins should return their output data to be sent to downstream plugins.\n",
    "          You can also call :func:`output()` as opposed to returning it.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(f\"plugin {type(self)} has not implemented process()\")\n",
    "    \n",
    "    def add(self, plugin, channel=0, **kwargs):\n",
    "        \"\"\"\n",
    "        Connect the output queue from this plugin with the input queue of another plugin,\n",
    "        so that this plugin sends its output data to the other one.\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "          plugin (Plugin|callable): either the plugin to link to, or a callback function.\n",
    "          channel (int) -- the output channel of this plugin to link the other plugin to.\n",
    "                        \n",
    "        Returns:\n",
    "\n",
    "          A reference to this plugin instance (self)\n",
    "        \"\"\"\n",
    "        class Callback(Plugin):\n",
    "            \"\"\"\n",
    "            Wrapper for calling a function with the same signature as Plugin.process()\n",
    "            This is automatically used by Plugin.add() so it's typically not needed.\n",
    "            Callbacks are threaded by default and will be run asynchronously.\n",
    "            If it's a lightweight non-blocking function, you can set threaded=False\n",
    "            \"\"\"\n",
    "            def __init__(self, function, threaded=False, **kwargs):\n",
    "                \"\"\"\n",
    "                Parameters:\n",
    "                  function (callable) -- function for processing data like Plugin.process() would\n",
    "                \"\"\"\n",
    "                super().__init__(threaded=threaded, **kwargs)\n",
    "                self.function = function\n",
    "                \n",
    "            def process(self, input, **kwargs):\n",
    "                return self.function(input, **kwargs)\n",
    "        \n",
    "        if not isinstance(plugin, Plugin):\n",
    "            if not callable(plugin):\n",
    "                raise TypeError(f\"{type(self)}.add() expects either a Plugin instance or a callable function (was {type(plugin)})\")\n",
    "            plugin = Callback(plugin, **kwargs)\n",
    "            \n",
    "        self.outputs[channel].append(plugin)\n",
    "        \n",
    "        if isinstance(plugin, Callback):\n",
    "            logging.debug(f\"connected {type(self).__name__} to {plugin.function.__name__} on channel={channel}\")  # TODO https://stackoverflow.com/a/25959545\n",
    "        else:\n",
    "            logging.debug(f\"connected {type(self).__name__} to {type(plugin).__name__} on channel={channel}\")\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def __call__(self, input=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Callable () operator alias for the :func:`input()` function.\n",
    "        This is provided for a more intuitive way of processing data \n",
    "        like ``plugin(data)`` instead of ``plugin.input(data)``\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "          input: input data sent to the plugin's :func:`process()` function.\n",
    "          kwargs: additional arguments forwarded to the plugin's :func:`process()` function.\n",
    "          \n",
    "        Returns:\n",
    "        \n",
    "          None if the plugin is threaded, otherwise returns any outputs.\n",
    "        \"\"\"\n",
    "        return self.input(input, **kwargs)\n",
    "        \n",
    "    def input(self, input=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Add data to the plugin's processing queue and return immediately,\n",
    "        or process it now and return the results if ``threaded=False``.\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "          input: input data sent to the plugin's :func:`process()` function.\n",
    "          kwargs: additional arguments forwarded to the plugin's :func:`process()` function.\n",
    "          \n",
    "        Returns:\n",
    "        \n",
    "          None if the plugin is threaded, otherwise returns any outputs.\n",
    "        \"\"\"\n",
    "        if self.threaded:\n",
    "            #self.start() # thread may not be started if plugin only called from a callback\n",
    "            if self.drop_inputs:\n",
    "                configs = []\n",
    "                while True:\n",
    "                    try:\n",
    "                        config_input, config_kwargs = self.input_queue.get(block=False)\n",
    "                        if config_input is None and len(config_kwargs) > 0:  # still apply config\n",
    "                            configs.append((config_input, config_kwargs))\n",
    "                    except queue.Empty:\n",
    "                        break\n",
    "                for config in configs:\n",
    "                    self.input_queue.put(config)\n",
    "                    self.input_event.set()\n",
    "\n",
    "            self.input_queue.put((input,kwargs))\n",
    "            self.input_event.set()\n",
    "        else:\n",
    "            self.dispatch(input, **kwargs)\n",
    "            \n",
    "    def output(self, output, channel=0, **kwargs):\n",
    "        \"\"\"\n",
    "        Output data to the next plugin(s) on the specified channel (-1 for all channels)\n",
    "        \"\"\"\n",
    "        if output is None:\n",
    "            return\n",
    "            \n",
    "        if channel >= 0:\n",
    "            for output_plugin in self.outputs[channel]:\n",
    "                output_plugin.input(output, **kwargs)\n",
    "        else:\n",
    "            for output_channel in self.outputs:\n",
    "                for output_plugin in output_channel:\n",
    "                    output_plugin.input(output, **kwargs)\n",
    "                    \n",
    "        return output\n",
    "     \n",
    "    @property\n",
    "    def num_outputs(self):\n",
    "        \"\"\"\n",
    "        Return the total number of output connections across all channels\n",
    "        \"\"\"\n",
    "        count = 0\n",
    "        for output_channel in self.outputs:\n",
    "            count += len(output_channel) \n",
    "        return count\n",
    "        \n",
    "    def start(self):\n",
    "        \"\"\"\n",
    "        Start threads for all plugins in the graph that have threading enabled.\n",
    "        \"\"\"\n",
    "        if self.threaded:\n",
    "            if not self.is_alive():\n",
    "                super().start()\n",
    "            \n",
    "        for output_channel in self.outputs:\n",
    "            for output in output_channel:\n",
    "                output.start()\n",
    "                \n",
    "        return self\n",
    "            \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Processes the queue forever and automatically run when created with ``threaded=True``\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            try:\n",
    "                self.input_event.wait()\n",
    "                self.input_event.clear()\n",
    "                \n",
    "                while True:\n",
    "                    try:\n",
    "                        input, kwargs = self.input_queue.get(block=False)\n",
    "                        self.dispatch(input, **kwargs)\n",
    "                    except queue.Empty:\n",
    "                        break\n",
    "            except Exception as error:\n",
    "                logging.error(f\"Exception occurred during processing of {type(self)}\\n\\n{traceback.format_exc()}\")\n",
    "\n",
    "    def dispatch(self, input, **kwargs):\n",
    "        \"\"\"\n",
    "        Invoke the process() function on incoming data\n",
    "        \"\"\"\n",
    "        if self.interrupted:\n",
    "            #logging.debug(f\"{type(self)} resetting interrupted flag to false\")\n",
    "            self.interrupted = False\n",
    "          \n",
    "        self.processing = True\n",
    "        outputs = self.process(input, **kwargs)\n",
    "        self.processing = False\n",
    "\n",
    "        self.output(outputs)\n",
    "        \n",
    "        if self.relay:\n",
    "            self.output(input)\n",
    "            \n",
    "        return outputs\n",
    "   \n",
    "    def interrupt(self, clear_inputs=True, recursive=True, block=None):\n",
    "        \"\"\"\n",
    "        Interrupt any ongoing/pending processing, and optionally clear the input queue\n",
    "        along with any downstream queues, and optionally wait for processing of those \n",
    "        requests to have finished.\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "          clear_inputs (bool):  if True, clear any remaining inputs in this plugin's queue.\n",
    "          recursive (bool):  if True, then any downstream plugins will also be interrupted.\n",
    "          block (bool):  is true, this function will wait until any ongoing processing has finished.\n",
    "                         This is done so that any lingering outputs don't cascade downstream in the pipeline.\n",
    "                         If block is None, it will automatically be set to true if this plugin has outputs.\n",
    "        \"\"\"\n",
    "        #logging.debug(f\"interrupting plugin {type(self)}  clear_inputs={clear_inputs} recursive={recursive} block={block}\")\n",
    "        \n",
    "        if clear_inputs:\n",
    "            self.clear_inputs()\n",
    "          \n",
    "        self.interrupted = True\n",
    "        \n",
    "        num_outputs = self.num_outputs\n",
    "        block_other = block\n",
    "        \n",
    "        if block is None and num_outputs > 0:\n",
    "            block = True\n",
    "            \n",
    "        while block and self.processing:\n",
    "            #logging.debug(f\"interrupt waiting for {type(self)} to complete processing\")\n",
    "            time.sleep(0.01) # TODO use an event for this?\n",
    "        \n",
    "        if recursive and num_outputs > 0:\n",
    "            for output_channel in self.outputs:\n",
    "                for output in output_channel:\n",
    "                    output.interrupt(clear_inputs=clear_inputs, recursive=recursive, block=block_other)\n",
    "                    \n",
    "    def clear_inputs(self):\n",
    "        \"\"\"\n",
    "        Clear the input queue, dropping any data.\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            try:\n",
    "                self.input_queue.get(block=False)\n",
    "            except queue.Empty:\n",
    "                return         \n",
    "\n",
    "    def find(self, type):\n",
    "        \"\"\"\n",
    "        Return the plugin with the specified type by searching for it among\n",
    "        the pipeline graph of inputs and output connections to other plugins.\n",
    "        \"\"\"\n",
    "        if isinstance(self, type):\n",
    "            return self\n",
    "            \n",
    "        for output_channel in self.outputs:\n",
    "            for output in output_channel:\n",
    "                if isinstance(output, type):\n",
    "                    return output\n",
    "                plugin = output.find(type)\n",
    "                if plugin is not None:\n",
    "                    return plugin\n",
    "            \n",
    "        return None\n",
    "    \n",
    "    '''\n",
    "    def __getitem__(self, type):\n",
    "        \"\"\"\n",
    "        Subscript indexing [] operator alias for find()\n",
    "        \"\"\"\n",
    "        return self.find(type)\n",
    "    '''       "
   ],
   "id": "5c8348cc23950179",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T14:30:15.661521Z",
     "start_time": "2024-05-01T14:30:15.634340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import logging\n",
    "import traceback\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from jetson_utils import videoSource, videoOutput, cudaDeviceSynchronize, cudaToNumpy\n",
    "\n",
    "\n",
    "class VideoSource(Plugin):\n",
    "    \"\"\"\n",
    "    Captures or loads a video/camera stream or sequence of images\n",
    "    https://github.com/dusty-nv/jetson-inference/blob/master/docs/aux-streaming.md\n",
    "    \"\"\"\n",
    "    def __init__(self, video_input='/dev/video0', \n",
    "                 video_input_width=None, video_input_height=None, \n",
    "                 video_input_codec=None, video_input_framerate=None, \n",
    "                 video_input_save=None, return_tensors='cuda', **kwargs):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        \n",
    "          input (str) -- path to video file, directory of images, or stream URL\n",
    "          input_width (int) -- the disired width in pixels (default uses stream's resolution)\n",
    "          input_height (int) -- the disired height in pixels (default uses stream's resolution)\n",
    "          input_codec (str) -- force a particular codec ('h264', 'h265', 'vp8', 'vp9', 'mjpeg', ect)\n",
    "          return_tensors (str) -- the object datatype of the image to output ('np', 'pt', 'cuda')\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        options = {}\n",
    "        \n",
    "        if video_input_width:\n",
    "            options['width'] = video_input_width\n",
    "            \n",
    "        if video_input_height:\n",
    "            options['height'] = video_input_height\n",
    "            \n",
    "        if video_input_codec:\n",
    "            options['codec'] = video_input_codec\n",
    " \n",
    "        if video_input_framerate:\n",
    "            options['framerate'] = video_input_framerate\n",
    "            \n",
    "        if video_input_save:\n",
    "            options['save'] = video_input_save\n",
    "        \n",
    "        self.stream = videoSource(video_input, options=options)\n",
    "        self.file = (self.stream.GetOptions()['resource']['protocol'] == 'file')\n",
    "        self.options = options\n",
    "        self.resource = video_input  # self.stream.GetOptions().resource['string']\n",
    "        self.return_tensors = return_tensors\n",
    "\n",
    "    def capture(self, timeout=2500, retries=8, return_tensors=None):\n",
    "        \"\"\"\n",
    "        Capture images from the video source as long as it's streaming\n",
    "        \"\"\"\n",
    "        if not return_tensors:\n",
    "            return_tensors = self.return_tensors\n",
    "            \n",
    "        retry = 0\n",
    "        \n",
    "        while retry < retries:\n",
    "            image = self.stream.Capture(format='rgb8', timeout=timeout)\n",
    "\n",
    "            if image is None:\n",
    "                if self.file:\n",
    "                    break\n",
    "                logging.warning(f\"video source {self.resource} timed out during capture, re-trying...\")\n",
    "                retry = retry + 1\n",
    "                continue\n",
    "   \n",
    "            if return_tensors == 'pt':\n",
    "                image = torch.as_tensor(image, device='cuda')\n",
    "            elif return_tensors == 'np':\n",
    "                image = cudaToNumpy(image)\n",
    "                cudaDeviceSynchronize()\n",
    "            elif return_tensors != 'cuda':\n",
    "                raise ValueError(f\"return_tensors should be 'np', 'pt', or 'cuda' (was '{return_tensors}')\")\n",
    "                \n",
    "            self.output(image)\n",
    "            return image\n",
    "    \n",
    "        return None\n",
    "        \n",
    "    def reconnect(self):\n",
    "        \"\"\"\n",
    "        Attempt to re-open the stream if the connection fails\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            try:\n",
    "                if self.stream is not None:\n",
    "                    self.stream.Close()\n",
    "                    self.stream = None        \n",
    "            except Exception as error:\n",
    "                logging.error(f\"Exception occurred closing video source \\\"{self.resource}\\\"\\n\\n{traceback.format_exc()}\")\n",
    "\n",
    "            try:\n",
    "                self.stream = videoSource(self.resource, options=self.options)\n",
    "                return\n",
    "            except Exception as error:\n",
    "                logging.error(f\"Failed to create video source \\\"{self.resource}\\\"\\n\\n{traceback.format_exc()}\")\n",
    "                time.sleep(2.5)\n",
    "            \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Run capture continuously and attempt to handle disconnections\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            try:\n",
    "                img = self.capture()\n",
    "            except Exception as error:\n",
    "                logging.error(f\"Exception occurred during video source capture of \\\"{self.resource}\\\"\\n\\n{traceback.format_exc()}\")\n",
    "            \n",
    "            if img is None:\n",
    "                if self.file:\n",
    "                    return\n",
    "                logging.error(f\"Re-initializing video source \\\"{self.resource}\\\"\")\n",
    "                self.reconnect()\n",
    "\n",
    "    @property\n",
    "    def streaming(self):\n",
    "        \"\"\"\n",
    "        Returns true if the stream is currently open, false if closed or EOS.\n",
    "        \"\"\"\n",
    "        return self.stream.IsStreaming()\n",
    "     \n",
    "    @property\n",
    "    def eos(self):\n",
    "        \"\"\"\n",
    "        Returns true if the stream is currently closed (EOS has been reached)\n",
    "        \"\"\"\n",
    "        return not self.streaming\n",
    "        \n",
    "class VideoOutput(Plugin):\n",
    "    \"\"\"\n",
    "    Saves images to a compressed video or directory of individual images, the display, or a network stream.\n",
    "    https://github.com/dusty-nv/jetson-inference/blob/master/docs/aux-streaming.md\n",
    "    \"\"\"\n",
    "    def __init__(self, video_output=None, video_output_codec=None, video_output_bitrate=None, video_output_save=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        \n",
    "          input (str) -- path to video file, directory of images, or stream URL\n",
    "          output_codec (str) -- force a particular codec ('h264', 'h265', 'vp8', 'vp9', 'mjpeg', ect)\n",
    "          output_bitrate (int) -- the desired bitrate in bits per second (default is 4 Mbps)\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        options = {}\n",
    "\n",
    "        if video_output_codec:\n",
    "            options['codec'] = video_output_codec\n",
    "            \n",
    "        if video_output_bitrate:\n",
    "            options['bitrate'] = video_output_bitrate\n",
    "\n",
    "        if video_output_save:\n",
    "            options['save'] = video_output_save\n",
    "            \n",
    "        if video_output is None:\n",
    "            video_output = ''\n",
    "            \n",
    "        args = None if 'display://' in video_output else ['--headless']\n",
    "        \n",
    "        self.stream = videoOutput(video_output, options=options, argv=args)\n",
    "        self.resource = video_output\n",
    "        \n",
    "    def process(self, input, **kwargs):\n",
    "        \"\"\"\n",
    "        Input should be a jetson_utils.cudaImage, np.ndarray, torch.Tensor, or have __cuda_array_interface__\n",
    "        \"\"\"\n",
    "        self.stream.Render(cuda_image(input))"
   ],
   "id": "74c60eedcac230ac",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T14:55:14.393112Z",
     "start_time": "2024-05-01T14:54:21.324375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def on_video(image):\n",
    "    num_frames = video_source.stream.GetFrameCount()\n",
    "    if num_frames % 25 == 0:\n",
    "        logging.info(f'captured {num_frames} frames ({image.width}x{image.height}) from {video_source.resource}')\n",
    "        \n",
    "video_source = VideoSource(video_input='file:///home/johnny/Projects/small-fast-detector/misc/repaired_file.mp4')\n",
    "\n",
    "video_source.add(on_video, threaded=False)\n",
    "videoOutput.Render()\n",
    "\n",
    "video_source.start().join()"
   ],
   "id": "7332a7a556bfde4d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gstreamer] gstDecoder -- creating decoder for /home/johnny/Projects/small-fast-detector/misc/repaired_file.mp4\n",
      "Opening in BLOCKING MODE \n",
      "[gstreamer] gstDecoder -- discovered video resolution: 960x540  (framerate 30.000000 Hz)\n",
      "[gstreamer] gstDecoder -- discovered video caps:  video/x-h264, stream-format=(string)byte-stream, alignment=(string)au, level=(string)3.1, profile=(string)high, width=(int)960, height=(int)540, framerate=(fraction)30/1, pixel-aspect-ratio=(fraction)1/1, chroma-format=(string)4:2:0, bit-depth-luma=(uint)8, bit-depth-chroma=(uint)8, parsed=(boolean)true\n",
      "[gstreamer] gstDecoder -- pipeline string:\n",
      "[gstreamer] filesrc location=/home/johnny/Projects/small-fast-detector/misc/repaired_file.mp4 ! qtdemux ! queue ! h264parse ! nvv4l2decoder name=decoder enable-max-performance=1 ! video/x-raw(memory:NVMM) ! nvvidconv name=vidconv ! video/x-raw ! appsink name=mysink\n",
      "\u001B[0;32m[video]  created gstDecoder from file:///home/johnny/Projects/small-fast-detector/misc/repaired_file.mp4\n",
      "\u001B[0m------------------------------------------------\n",
      "gstDecoder video options:\n",
      "------------------------------------------------\n",
      "  -- URI: file:///home/johnny/Projects/small-fast-detector/misc/repaired_file.mp4\n",
      "     - protocol:  file\n",
      "     - location:  /home/johnny/Projects/small-fast-detector/misc/repaired_file.mp4\n",
      "     - extension: mp4\n",
      "  -- deviceType: file\n",
      "  -- ioType:     input\n",
      "  -- codec:      H264\n",
      "  -- codecType:  v4l2\n",
      "  -- width:      960\n",
      "  -- height:     540\n",
      "  -- frameRate:  30\n",
      "  -- numBuffers: 4\n",
      "  -- zeroCopy:   true\n",
      "  -- flipMethod: none\n",
      "  -- loop:       0\n",
      "------------------------------------------------\n",
      "[gstreamer] gstDecoder -- stopping pipeline, transitioning to GST_STATE_NULL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NvMMLiteOpen : Block : BlockType = 261 \n",
      "NvMMLiteBlockCreate : Block : BlockType = 261 \n",
      "\n",
      "(python:6921): GStreamer-CRITICAL **: 16:54:21.369: gst_debug_log_valist: assertion 'category != NULL' failed\n",
      "\n",
      "(python:6921): GStreamer-CRITICAL **: 16:54:21.369: gst_debug_log_valist: assertion 'category != NULL' failed\n",
      "\n",
      "(python:6921): GStreamer-CRITICAL **: 16:54:21.369: gst_debug_log_valist: assertion 'category != NULL' failed\n",
      "\n",
      "(python:6921): GStreamer-CRITICAL **: 16:54:21.369: gst_debug_log_valist: assertion 'category != NULL' failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gstreamer] gstDecoder -- pipeline stopped\n",
      "[gstreamer] opening gstDecoder for streaming, transitioning pipeline to GST_STATE_PLAYING\n",
      "Opening in BLOCKING MODE \n",
      "[gstreamer] gstreamer changed state from NULL to READY ==> mysink\n",
      "[gstreamer] gstreamer changed state from NULL to READY ==> capsfilter10\n",
      "[gstreamer] gstreamer changed state from NULL to READY ==> vidconv\n",
      "[gstreamer] gstreamer changed state from NULL to READY ==> capsfilter9\n",
      "[gstreamer] gstreamer changed state from NULL to READY ==> decoder\n",
      "[gstreamer] gstreamer changed state from NULL to READY ==> h264parse1\n",
      "[gstreamer] gstreamer changed state from NULL to READY ==> queue2\n",
      "[gstreamer] gstreamer changed state from NULL to READY ==> qtdemux3\n",
      "[gstreamer] gstreamer changed state from NULL to READY ==> filesrc2\n",
      "[gstreamer] gstreamer changed state from NULL to READY ==> pipeline3\n",
      "[gstreamer] gstreamer changed state from READY to PAUSED ==> capsfilter10\n",
      "[gstreamer] gstreamer changed state from READY to PAUSED ==> vidconv\n",
      "[gstreamer] gstreamer changed state from READY to PAUSED ==> capsfilter9\n",
      "[gstreamer] gstreamer changed state from READY to PAUSED ==> decoder\n",
      "[gstreamer] gstreamer changed state from READY to PAUSED ==> h264parse1\n",
      "[gstreamer] gstreamer stream status CREATE ==> src\n",
      "[gstreamer] gstreamer changed state from READY to PAUSED ==> queue2\n",
      "[gstreamer] gstreamer stream status ENTER ==> src\n",
      "[gstreamer] gstreamer stream status CREATE ==> sink\n",
      "[gstreamer] gstreamer changed state from READY to PAUSED ==> qtdemux3\n",
      "[gstreamer] gstreamer changed state from READY to PAUSED ==> filesrc2\n",
      "[gstreamer] gstreamer stream status ENTER ==> sink\n",
      "[gstreamer] gstreamer message stream-start ==> pipeline3\n",
      "[gstreamer] gstreamer message duration-changed ==> h264parse1\n",
      "[gstreamer] gstDecoder -- onPreroll()\n",
      "[gstreamer] gstreamer stream status CREATE ==> src\n",
      "[gstreamer] gstreamer stream status ENTER ==> src\n",
      "[gstreamer] gstreamer mysink taglist, video-codec=(string)\"H.264\\ /\\ AVC\", maximum-bitrate=(uint)1357879, bitrate=(uint)1357879;\n",
      "[gstreamer] gstreamer mysink taglist, encoder=(string)Lavf58.76.100, container-format=(string)\"ISO\\ MP4/M4A\";\n",
      "[gstreamer] gstreamer mysink taglist, video-codec=(string)\"H.264\\ \\(High\\ Profile\\)\", maximum-bitrate=(uint)1357879, bitrate=(uint)1357879;\n",
      "\u001B[0;33m[gstreamer] gstBufferManager -- map buffer size was less than max size (777600 vs 777607)\n",
      "\u001B[0m[gstreamer] gstBufferManager recieve caps:  video/x-raw, width=(int)960, height=(int)540, interlace-mode=(string)progressive, multiview-mode=(string)mono, multiview-flags=(GstVideoMultiviewFlagsSet)0:ffffffff:/right-view-first/left-flipped/left-flopped/right-flipped/right-flopped/half-aspect/mixed-mono, pixel-aspect-ratio=(fraction)1/1, framerate=(fraction)30/1, nvbuf-memory-type=(string)nvbuf-mem-surface-array, gpu-id=(int)0, format=(string)NV12\n",
      "[gstreamer] gstBufferManager -- recieved first frame, codec=H264 format=nv12 width=960 height=540 size=777607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NvMMLiteOpen : Block : BlockType = 261 \n",
      "NvMMLiteBlockCreate : Block : BlockType = 261 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cuda]   allocated 4 ring buffers (777607 bytes each, 3110428 bytes total)\n",
      "[cuda]   allocated 4 ring buffers (8 bytes each, 32 bytes total)\n",
      "[gstreamer] gstreamer changed state from READY to PAUSED ==> mysink\n",
      "[gstreamer] gstreamer changed state from READY to PAUSED ==> pipeline3\n",
      "[gstreamer] gstreamer message async-done ==> pipeline3\n",
      "[gstreamer] gstreamer message latency ==> mysink\n",
      "[gstreamer] gstreamer message new-clock ==> pipeline3\n",
      "[gstreamer] gstreamer changed state from PAUSED to PLAYING ==> mysink\n",
      "[gstreamer] gstreamer changed state from PAUSED to PLAYING ==> capsfilter10\n",
      "[gstreamer] gstreamer changed state from PAUSED to PLAYING ==> vidconv\n",
      "[gstreamer] gstreamer changed state from PAUSED to PLAYING ==> capsfilter9\n",
      "[gstreamer] gstreamer changed state from PAUSED to PLAYING ==> decoder\n",
      "[gstreamer] gstreamer changed state from PAUSED to PLAYING ==> h264parse1\n",
      "[gstreamer] gstreamer changed state from PAUSED to PLAYING ==> queue2\n",
      "[gstreamer] gstreamer changed state from PAUSED to PLAYING ==> qtdemux3\n",
      "[gstreamer] gstreamer changed state from PAUSED to PLAYING ==> filesrc2\n",
      "[gstreamer] gstreamer changed state from PAUSED to PLAYING ==> pipeline3\n",
      "[cuda]   allocated 4 ring buffers (1555200 bytes each, 6220800 bytes total)\n",
      "[gstreamer] gstreamer mysink taglist, video-codec=(string)\"H.264\\ \\(High\\ Profile\\)\", maximum-bitrate=(uint)1357879, bitrate=(uint)1357879, minimum-bitrate=(uint)400320;\n",
      "[gstreamer] gstreamer mysink taglist, video-codec=(string)\"H.264\\ \\(High\\ Profile\\)\", maximum-bitrate=(uint)1357879, bitrate=(uint)1357879, minimum-bitrate=(uint)314880;\n",
      "[gstreamer] gstreamer mysink taglist, video-codec=(string)\"H.264\\ \\(High\\ Profile\\)\", maximum-bitrate=(uint)1357879, bitrate=(uint)1357879, minimum-bitrate=(uint)266160;\n",
      "[gstreamer] gstreamer mysink taglist, video-codec=(string)\"H.264\\ \\(High\\ Profile\\)\", maximum-bitrate=(uint)1357879, bitrate=(uint)1357879, minimum-bitrate=(uint)244560;\n",
      "[gstreamer] gstreamer mysink taglist, video-codec=(string)\"H.264\\ \\(High\\ Profile\\)\", maximum-bitrate=(uint)1357879, bitrate=(uint)1357879, minimum-bitrate=(uint)225600;\n",
      "[gstreamer] gstreamer mysink taglist, video-codec=(string)\"H.264\\ \\(High\\ Profile\\)\", maximum-bitrate=(uint)1357879, bitrate=(uint)1357879, minimum-bitrate=(uint)214080;\n",
      "[gstreamer] gstreamer mysink taglist, video-codec=(string)\"H.264\\ \\(High\\ Profile\\)\", maximum-bitrate=(uint)1357879, bitrate=(uint)1357879, minimum-bitrate=(uint)209520;\n",
      "\u001B[0;33m[gstreamer] gstDecoder -- end of stream (EOS)\n",
      "\u001B[0m\u001B[0;33m[gstreamer] gstDecoder::Capture() -- a timeout occurred waiting for the next image buffer\n",
      "\u001B[0m"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T15:17:31.463332Z",
     "start_time": "2024-05-01T15:16:38.589668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!export DISPLAY=:0\n",
    "!xinit &\n",
    "import logging\n",
    "\n",
    "# Asumimos que ya tienes importadas las clases necesarias, como videoSource y videoOutput\n",
    "from jetson_utils import videoSource, videoOutput\n",
    "\n",
    "def main():\n",
    "    # Configura la fuente del video y el output\n",
    "    video_input = 'file:///home/johnny/Projects/small-fast-detector/misc/repaired_file.mp4'\n",
    "    video_output = 'display://0'\n",
    "\n",
    "    # Crea las instancias de VideoSource y VideoOutput\n",
    "    source = videoSource(video_input)  # Asume que hay parámetros predeterminados adecuados\n",
    "    output = videoOutput(video_output)  # Asume que hay parámetros predeterminados adecuados\n",
    "\n",
    "    # Bucle para capturar y renderizar el vídeo frame por frame\n",
    "    try:\n",
    "        while source.IsStreaming():\n",
    "            frame = source.Capture()  # Captura un frame\n",
    "            if frame is not None:\n",
    "                output.Render(frame)  # Renderiza el frame\n",
    "            else:\n",
    "                break  # Sale del bucle si no hay más frames\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupción por parte del usuario.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Ocurrió un error durante la captura y renderización del video: {str(e)}\")\n",
    "\n",
    "    # Limpieza: Asegúrate de cerrar adecuadamente los recursos\n",
    "    source.Close()\n",
    "    output.Close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "8f1423998e6f95c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gstreamer] gstDecoder -- creating decoder for /home/johnny/Projects/small-fast-detector/misc/repaired_file.mp4\n",
      "Opening in BLOCKING MODE \n",
      "[gstreamer] gstDecoder -- discovered video resolution: 960x540  (framerate 30.000000 Hz)\n",
      "[gstreamer] gstDecoder -- discovered video caps:  video/x-h264, stream-format=(string)byte-stream, alignment=(string)au, level=(string)3.1, profile=(string)high, width=(int)960, height=(int)540, framerate=(fraction)30/1, pixel-aspect-ratio=(fraction)1/1, chroma-format=(string)4:2:0, bit-depth-luma=(uint)8, bit-depth-chroma=(uint)8, parsed=(boolean)true\n",
      "[gstreamer] gstDecoder -- pipeline string:\n",
      "[gstreamer] filesrc location=/home/johnny/Projects/small-fast-detector/misc/repaired_file.mp4 ! qtdemux ! queue ! h264parse ! nvv4l2decoder name=decoder enable-max-performance=1 ! video/x-raw(memory:NVMM) ! nvvidconv name=vidconv ! video/x-raw ! appsink name=mysink\n",
      "\u001B[0;32m[video]  created gstDecoder from file:///home/johnny/Projects/small-fast-detector/misc/repaired_file.mp4\n",
      "\u001B[0m------------------------------------------------\n",
      "gstDecoder video options:\n",
      "------------------------------------------------\n",
      "  -- URI: file:///home/johnny/Projects/small-fast-detector/misc/repaired_file.mp4\n",
      "     - protocol:  file\n",
      "     - location:  /home/johnny/Projects/small-fast-detector/misc/repaired_file.mp4\n",
      "     - extension: mp4\n",
      "  -- deviceType: file\n",
      "  -- ioType:     input\n",
      "  -- codec:      H264\n",
      "  -- codecType:  v4l2\n",
      "  -- width:      960\n",
      "  -- height:     540\n",
      "  -- frameRate:  30\n",
      "  -- numBuffers: 4\n",
      "  -- zeroCopy:   true\n",
      "  -- flipMethod: none\n",
      "  -- loop:       0\n",
      "------------------------------------------------\n",
      "[OpenGL] glDisplay -- X screen 0 resolution:  1920x1080\n",
      "[OpenGL] glDisplay -- X window resolution:    1920x1080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NvMMLiteOpen : Block : BlockType = 261 \n",
      "NvMMLiteBlockCreate : Block : BlockType = 261 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OpenGL] glDisplay -- display device initialized (1920x1080)\n",
      "\u001B[0;32m[video]  created glDisplay from display://0\n",
      "\u001B[0m------------------------------------------------\n",
      "glDisplay video options:\n",
      "------------------------------------------------\n",
      "  -- URI: display://0\n",
      "     - protocol:  display\n",
      "     - location:  0\n",
      "  -- deviceType: display\n",
      "  -- ioType:     output\n",
      "  -- width:      1920\n",
      "  -- height:     1080\n",
      "  -- frameRate:  0\n",
      "  -- numBuffers: 4\n",
      "  -- zeroCopy:   true\n",
      "------------------------------------------------\n",
      "[gstreamer] opening gstDecoder for streaming, transitioning pipeline to GST_STATE_PLAYING\n",
      "Opening in BLOCKING MODE \n",
      "[gstreamer] gstreamer changed state from NULL to READY ==> mysink\n",
      "[gstreamer] gstreamer changed state from NULL to READY ==> capsfilter16\n",
      "[gstreamer] gstreamer changed state from NULL to READY ==> vidconv\n",
      "[gstreamer] gstreamer changed state from NULL to READY ==> capsfilter15\n",
      "[gstreamer] gstreamer changed state from NULL to READY ==> decoder\n",
      "[gstreamer] gstreamer changed state from NULL to READY ==> h264parse5\n",
      "[gstreamer] gstreamer changed state from NULL to READY ==> queue4\n",
      "[gstreamer] gstreamer changed state from NULL to READY ==> qtdemux7\n",
      "[gstreamer] gstreamer changed state from NULL to READY ==> filesrc4\n",
      "[gstreamer] gstreamer changed state from NULL to READY ==> pipeline5\n",
      "[gstreamer] gstreamer changed state from READY to PAUSED ==> capsfilter16\n",
      "[gstreamer] gstreamer changed state from READY to PAUSED ==> vidconv\n",
      "[gstreamer] gstreamer changed state from READY to PAUSED ==> capsfilter15\n",
      "[gstreamer] gstreamer changed state from READY to PAUSED ==> decoder\n",
      "[gstreamer] gstreamer changed state from READY to PAUSED ==> h264parse5\n",
      "[gstreamer] gstreamer stream status CREATE ==> src\n",
      "[gstreamer] gstreamer changed state from READY to PAUSED ==> queue4\n",
      "[gstreamer] gstreamer stream status ENTER ==> src\n",
      "[gstreamer] gstreamer stream status CREATE ==> sink\n",
      "[gstreamer] gstreamer changed state from READY to PAUSED ==> qtdemux7\n",
      "[gstreamer] gstreamer changed state from READY to PAUSED ==> filesrc4\n",
      "[gstreamer] gstreamer stream status ENTER ==> sink\n",
      "[gstreamer] gstreamer message stream-start ==> pipeline5\n",
      "[gstreamer] gstreamer message duration-changed ==> h264parse5\n",
      "[gstreamer] gstDecoder -- onPreroll()\n",
      "[gstreamer] gstreamer stream status CREATE ==> src\n",
      "[gstreamer] gstreamer stream status ENTER ==> src\n",
      "[gstreamer] gstreamer mysink taglist, video-codec=(string)\"H.264\\ /\\ AVC\", maximum-bitrate=(uint)1357879, bitrate=(uint)1357879;\n",
      "[gstreamer] gstreamer mysink taglist, encoder=(string)Lavf58.76.100, container-format=(string)\"ISO\\ MP4/M4A\";\n",
      "[gstreamer] gstreamer mysink taglist, video-codec=(string)\"H.264\\ \\(High\\ Profile\\)\", maximum-bitrate=(uint)1357879, bitrate=(uint)1357879;\n",
      "\u001B[0;33m[gstreamer] gstBufferManager -- map buffer size was less than max size (777600 vs 777607)\n",
      "\u001B[0m[gstreamer] gstBufferManager recieve caps:  video/x-raw, width=(int)960, height=(int)540, interlace-mode=(string)progressive, multiview-mode=(string)mono, multiview-flags=(GstVideoMultiviewFlagsSet)0:ffffffff:/right-view-first/left-flipped/left-flopped/right-flipped/right-flopped/half-aspect/mixed-mono, pixel-aspect-ratio=(fraction)1/1, framerate=(fraction)30/1, nvbuf-memory-type=(string)nvbuf-mem-surface-array, gpu-id=(int)0, format=(string)NV12\n",
      "[gstreamer] gstBufferManager -- recieved first frame, codec=H264 format=nv12 width=960 height=540 size=777607\n",
      "[cuda]   allocated 4 ring buffers (777607 bytes each, 3110428 bytes total)\n",
      "[cuda]   allocated 4 ring buffers (8 bytes each, 32 bytes total)\n",
      "[gstreamer] gstreamer changed state from READY to PAUSED ==> mysink\n",
      "[gstreamer] gstreamer changed state from READY to PAUSED ==> pipeline5\n",
      "[gstreamer] gstreamer message async-done ==> pipeline5\n",
      "[gstreamer] gstreamer message latency ==> mysink\n",
      "[gstreamer] gstreamer message new-clock ==> pipeline5\n",
      "[gstreamer] gstreamer changed state from PAUSED to PLAYING ==> mysink\n",
      "[gstreamer] gstreamer changed state from PAUSED to PLAYING ==> capsfilter16\n",
      "[gstreamer] gstreamer changed state from PAUSED to PLAYING ==> vidconv\n",
      "[gstreamer] gstreamer changed state from PAUSED to PLAYING ==> capsfilter15\n",
      "[gstreamer] gstreamer changed state from PAUSED to PLAYING ==> decoder\n",
      "[gstreamer] gstreamer changed state from PAUSED to PLAYING ==> h264parse5\n",
      "[gstreamer] gstreamer changed state from PAUSED to PLAYING ==> queue4\n",
      "[gstreamer] gstreamer changed state from PAUSED to PLAYING ==> qtdemux7\n",
      "[gstreamer] gstreamer changed state from PAUSED to PLAYING ==> filesrc4\n",
      "[gstreamer] gstreamer changed state from PAUSED to PLAYING ==> pipeline5\n",
      "[cuda]   allocated 4 ring buffers (1555200 bytes each, 6220800 bytes total)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NvMMLiteOpen : Block : BlockType = 261 \n",
      "NvMMLiteBlockCreate : Block : BlockType = 261 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gstreamer] gstreamer mysink taglist, video-codec=(string)\"H.264\\ \\(High\\ Profile\\)\", maximum-bitrate=(uint)1357879, bitrate=(uint)1357879, minimum-bitrate=(uint)400320;\n",
      "[gstreamer] gstreamer mysink taglist, video-codec=(string)\"H.264\\ \\(High\\ Profile\\)\", maximum-bitrate=(uint)1357879, bitrate=(uint)1357879, minimum-bitrate=(uint)314880;\n",
      "[gstreamer] gstreamer mysink taglist, video-codec=(string)\"H.264\\ \\(High\\ Profile\\)\", maximum-bitrate=(uint)1357879, bitrate=(uint)1357879, minimum-bitrate=(uint)266160;\n",
      "[gstreamer] gstreamer mysink taglist, video-codec=(string)\"H.264\\ \\(High\\ Profile\\)\", maximum-bitrate=(uint)1357879, bitrate=(uint)1357879, minimum-bitrate=(uint)244560;\n",
      "[gstreamer] gstreamer mysink taglist, video-codec=(string)\"H.264\\ \\(High\\ Profile\\)\", maximum-bitrate=(uint)1357879, bitrate=(uint)1357879, minimum-bitrate=(uint)225600;\n",
      "[gstreamer] gstreamer mysink taglist, video-codec=(string)\"H.264\\ \\(High\\ Profile\\)\", maximum-bitrate=(uint)1357879, bitrate=(uint)1357879, minimum-bitrate=(uint)214080;\n",
      "[gstreamer] gstreamer mysink taglist, video-codec=(string)\"H.264\\ \\(High\\ Profile\\)\", maximum-bitrate=(uint)1357879, bitrate=(uint)1357879, minimum-bitrate=(uint)209520;\n",
      "\u001B[0;33m[gstreamer] gstDecoder -- end of stream (EOS)\n",
      "\u001B[0m\u001B[0;33m[gstreamer] gstDecoder::Capture() -- a timeout occurred waiting for the next image buffer\n",
      "\u001B[0m"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "401771933d8f0e65"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
